{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH = 3\n",
    "class Environment:\n",
    "    def __init__(self, board = None):\n",
    "        self.x = 1\n",
    "        self.o = -1\n",
    "        self.board = np.zeros((LENGTH, LENGTH))\n",
    "        self.winner = None\n",
    "        self.num_states = 3 ** (LENGTH * LENGTH)\n",
    "    \n",
    "    def game_over(self):\n",
    "        # Check the rows to see if any player aligned 3 pieces\n",
    "        for i in range(LENGTH):\n",
    "            row_sum = self.board[i, :].sum()\n",
    "            if row_sum == LENGTH:\n",
    "                self.winner = self.x\n",
    "                return True\n",
    "            if row_sum == -LENGTH:\n",
    "                self.winner = self.o\n",
    "                return True\n",
    "        # Check columns\n",
    "        for j in range(LENGTH):\n",
    "            col_sum = self.board[:, j].sum()\n",
    "            if col_sum == LENGTH:\n",
    "                self.winner = self.x\n",
    "                return True\n",
    "            if col_sum == -LENGTH:\n",
    "                self.winner = self.o\n",
    "                return True\n",
    "            \n",
    "        # Check main diagonal\n",
    "        diag_sum = self.board.trace()\n",
    "        if diag_sum == LENGTH:\n",
    "            self.winner = self.x\n",
    "            return True\n",
    "        if diag_sum == -LENGTH:\n",
    "            self.winner = self.o\n",
    "            return True\n",
    "        \n",
    "        # Check the second diagonal\n",
    "        opp_diag_sum = np.fliplr(self.board).trace()\n",
    "        if opp_diag_sum == LENGTH:\n",
    "            self.winner = self.x\n",
    "            return True\n",
    "        if opp_diag_sum == -LENGTH:\n",
    "            self.winner = self.o\n",
    "            return True\n",
    "        \n",
    "        # If none of the above is true, check if the grid is full\n",
    "        for i in range(LENGTH):\n",
    "            for j in range(LENGTH):\n",
    "                if self.is_empty(i, j):\n",
    "                    return False\n",
    "        return True\n",
    "    \n",
    "    def draw_board(self):\n",
    "        print('-------------------------')\n",
    "        for i in range(LENGTH):\n",
    "            for j in range(LENGTH):\n",
    "                print('|', end = '   ')\n",
    "                if self.board[i, j] == self.x:\n",
    "                    print('x', end = '   ')\n",
    "                elif self.board[i, j] == self.o:\n",
    "                    print('o', end = '   ')\n",
    "                else:\n",
    "                    print(' ', end = '   ')\n",
    "            print('|', end = '\\n')\n",
    "            print('-------------------------')\n",
    "    \n",
    "    # The state is an integer obtained by considering the grid as a number in base 3, then converting this number to the decimal base\n",
    "    # e.g:\n",
    "    #-------------------------\n",
    "    #|   x   |       |       |\n",
    "    #-------------------------       state = 3^0 * 1 + 3^1 * 0 + 3^2 * 0 + 3^3 * 0 + 3^4 * 1 + ... + 3^7 * 2 + 3^8 * 2 = 17578\n",
    "    #|       |   x   |       |\n",
    "    #-------------------------\n",
    "    #|       |   o   |   o   |\n",
    "    #------------------------\n",
    "    def get_state(self):\n",
    "        result = 0\n",
    "        power = 0\n",
    "        for i in range(LENGTH):\n",
    "            for j in range(LENGTH):\n",
    "                value = 0\n",
    "                if self.board[i, j] == self.x:\n",
    "                    value = 1\n",
    "                elif self.board[i, j] == self.o:\n",
    "                    value = 2\n",
    "                result += (3 ** power) * value\n",
    "                power += 1\n",
    "        return result\n",
    "    \n",
    "    def set_board(self, board):\n",
    "        self.board = board\n",
    "        \n",
    "    # Converts a state (number) to a board (3x3 grid) by finding the representation of the state in base 3\n",
    "    def convert_state_to_board(self, state):\n",
    "        # grid of length 9 that will contain the base 3 representation of the state\n",
    "        grid = np.zeros(LENGTH * LENGTH)\n",
    "        i = 0\n",
    "        # Division algorithm to go from base 10 to another base\n",
    "        while state >= 3:\n",
    "            grid[i] = state % 3\n",
    "            state //= 3\n",
    "            i += 1\n",
    "        grid[i] = state\n",
    "        # Replace the '1' and '2' by the actual symbols for x and o\n",
    "        grid = np.where(grid == 1, self.x, grid)\n",
    "        grid = np.where(grid == 2, self.o, grid)\n",
    "        \n",
    "        grid = grid.reshape((LENGTH, LENGTH))\n",
    "        \n",
    "        return grid\n",
    "    \n",
    "    def is_empty(self, i, j):\n",
    "        return self.board[i, j] == 0\n",
    "    \n",
    "    # The player gets a reward only if he wins the game, otherwise he doesn't get any\n",
    "    def reward(self, symbol):\n",
    "        if self.game_over() and self.winner == symbol:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def reset(self):\n",
    "        self.winner = None\n",
    "        self.board = np.zeros((LENGTH, LENGTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "|   x   |       |       |\n",
      "-------------------------\n",
      "|       |   x   |       |\n",
      "-------------------------\n",
      "|       |   o   |   o   |\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment()\n",
    "env.board[0, 0] = 1\n",
    "env.board[1, 1] = 1\n",
    "env.board[2, 1] = -1\n",
    "env.board[2, 2] = -1\n",
    "env.draw_board()\n",
    "env.game_over()\n",
    "env.reward(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, eps, alpha, symbol, verbose = False):\n",
    "        self.eps = eps    # for epsilon-greedy algorithm\n",
    "        self.alpha = alpha    # learning rate\n",
    "        self.verbose = verbose    # wether or not the internal behaviours should be reported\n",
    "        self.symbol = symbol    # empty, 'x' = 1 or 'o' = -1\n",
    "        self.state_history = []    # all the states we went through during a game\n",
    "        self.value_function = {}    # (state, value) mapping, saved as a dictionary\n",
    "        self.set_value_function_iterative()    # calls the set_value_function method that finds the values of all possible states\n",
    "    \n",
    "    # helper method\n",
    "    def set_value_function_recursive_helper(self):\n",
    "        if self.verbose:\n",
    "            print('Initializing value function recursively...')\n",
    "        self.set_value_function_in(Environment(), self.value_function, 0, 0)\n",
    "        \n",
    "    def set_symbol(self, symbol):\n",
    "        self.symbol = symbol\n",
    "        \n",
    "    def set_verbose(self, verbose):\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    # finds values of all possible states, given the current environment (current board) and the coordinates of the next symbol to be placd on the grid\n",
    "    def set_value_function_recursive(self, env, value_dict, i, j):\n",
    "        for symbol in [env.x, env.o, 0]:\n",
    "            env.board[i, j] = symbol\n",
    "            # Find the (state, value) pair\n",
    "            state = env.get_state()\n",
    "            value = 0\n",
    "            if env.game_over():\n",
    "                if env.winner == self.symbol:\n",
    "                    value = 1\n",
    "                else:\n",
    "                    value = 0\n",
    "            else:\n",
    "                value = 0.5\n",
    "\n",
    "            # save the (state, value) pair in the dictionary\n",
    "            value_dict[state] = value\n",
    "\n",
    "            # Find the next coordinates and only recurse if (i, j) != (2, 2)\n",
    "            if i < LENGTH - 1:\n",
    "                if j < LENGTH - 1:\n",
    "                    next_i = i\n",
    "                    next_j = j + 1\n",
    "                else:\n",
    "                    next_i = i + 1\n",
    "                    next_j = 0\n",
    "                self.set_value_function_recursive(env, value_dict, next_i, next_j)\n",
    "            else:\n",
    "                if j < LENGTH - 1:\n",
    "                    next_i = i\n",
    "                    next_j = j + 1\n",
    "                    self.set_value_function_recursive(env, value_dict, next_i, next_j)   \n",
    "                    \n",
    "    # More efficient way of finding the value function (without recursion)         \n",
    "    def set_value_function_iterative(self):\n",
    "        if self.verbose:\n",
    "            print('Initializing value function iteratively...')\n",
    "        env = Environment()\n",
    "        self.value_function = {}\n",
    "        for state in range(env.num_states):\n",
    "            # Convert the state (number) to a board (3x3 grid)\n",
    "            board = env.convert_state_to_board(state)\n",
    "            # Set the new board to be the board of our environment\n",
    "            env.set_board(board)\n",
    "            # Find the initial value (1 if win, 0 if lose or draw, 0.5 otherwise)\n",
    "            value = 0\n",
    "            if env.game_over():\n",
    "                if env.winner == self.symbol:\n",
    "                    value = 1\n",
    "                else:\n",
    "                    value = 0\n",
    "            else:\n",
    "                value = 0.5\n",
    "            # Save the (state, value) pair in the value function dictionary\n",
    "            self.value_function[state] = value\n",
    "            \n",
    "    def take_action(self, env, training_mode = True):\n",
    "        # find the posible actions (empty cells) the agent can take\n",
    "        actions = []\n",
    "        values = []\n",
    "        for i in range(LENGTH):\n",
    "            for j in range(LENGTH):\n",
    "                if env.board[i, j] == 0:\n",
    "                    actions.append((i, j))\n",
    "        \n",
    "        action = (0, 0)\n",
    "        # epsilon-greedy algorithm\n",
    "        r = np.random.random()\n",
    "        if r < self.eps and training_mode:\n",
    "            # take a random action (exploration, only when training)\n",
    "            if self.verbose:\n",
    "                print('Taking random action')\n",
    "            action_index = np.random.choice(len(actions))\n",
    "            action = actions[action_index]\n",
    "        else:\n",
    "            # Find the action with the maximum value\n",
    "            if self.verbose:\n",
    "                print('Finding action with maximum value')\n",
    "            max_value = -1\n",
    "            max_action = (0, 0)\n",
    "            for (i, j) in actions:\n",
    "                env.board[i, j] = self.symbol\n",
    "                state = env.get_state()\n",
    "                value = self.value_function[state]\n",
    "                values.append(value)\n",
    "                if value > max_value:\n",
    "                    max_value = value\n",
    "                    max_action = (i, j)\n",
    "                env.board[i, j] = 0\n",
    "            \n",
    "            if self.verbose:\n",
    "                # Printing board with the values of each possible action (Not  necessary)\n",
    "                print('-------------------------')\n",
    "                for i in range(LENGTH):\n",
    "                    for j in range(LENGTH):\n",
    "                        print('|', end = ' ')\n",
    "                        if env.board[i, j] == env.x:\n",
    "                            print('  x', end = '   ')\n",
    "                        elif env.board[i, j] == env.o:\n",
    "                            print('  o', end = '   ')\n",
    "                        else:\n",
    "                            print(' {:0.2f}'.format(values[actions.index((i, j))]), end = ' ')\n",
    "                    print('|', end = '\\n')\n",
    "                    print('-------------------------')\n",
    "                \n",
    "            action = max_action\n",
    "        \n",
    "        # Place symbol on the selected action\n",
    "        env.board[action] = self.symbol\n",
    "        \n",
    "        # Update state history\n",
    "        self.update_state_history(env.get_state())\n",
    "    \n",
    "    # Saves each state reached by the agent (in order)\n",
    "    def update_state_history(self, state):\n",
    "        self.state_history.append(state)\n",
    "    \n",
    "    # Updates the value functions with the formula:\n",
    "    #    V(s) = V(s) + alpha(V(s') - V(s))\n",
    "    def update(self):\n",
    "        #print(self.state_history)\n",
    "        #print('Old values:')\n",
    "        #for state in self.state_history:\n",
    "        #    print(self.value_function[state], end = ' ')\n",
    "        #print()\n",
    "        for i in range(len(self.state_history) - 2, -1, -1):\n",
    "            state = self.state_history[i]\n",
    "            next_state = self.state_history[i + 1]\n",
    "            self.value_function[state] += self.alpha * (self.value_function[next_state] - self.value_function[state])\n",
    "        #print('---------------------------')\n",
    "        #print('New values:')\n",
    "        #for state in self.state_history:\n",
    "        #    print(self.value_function[state], end = ' ')\n",
    "        #print('\\n-----------------------------')\n",
    "            \n",
    "    def reset_history(self):\n",
    "        self.state_history = []\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play one game\n",
    "def play_game(p1, p2, env, verbose = False, training_mode = True):\n",
    "    # Keep switching between players until the game is over\n",
    "    while not env.game_over():\n",
    "        if verbose:\n",
    "            print('Player 1 turn:')\n",
    "            \n",
    "        # since take_action only updates the state history of player 1, we should update player 2\n",
    "        #    history manually\n",
    "        p1.take_action(env, training_mode)\n",
    "        p2.update_state_history(env.get_state())\n",
    "        \n",
    "        \n",
    "        if verbose:\n",
    "            env.draw_board()\n",
    "        \n",
    "        # In case player 1 won before player 2 had to play\n",
    "        if env.game_over():\n",
    "            break\n",
    "        \n",
    "        if verbose:\n",
    "            print('Player 2 turn:')\n",
    "        \n",
    "        # since take_action only updates the state history of player 2, we should update player 1\n",
    "        #    history manually\n",
    "        p2.take_action(env, training_mode)\n",
    "        p1.update_state_history(env.get_state())\n",
    "        \n",
    "        if verbose:\n",
    "            env.draw_board()\n",
    "    # print results\n",
    "    if verbose:\n",
    "        if env.winner == None:\n",
    "            print('Game Over. Draw')\n",
    "        elif env.winner == p1.symbol:\n",
    "            print('Game Over. Player 1 wins')\n",
    "        else:\n",
    "            print('Game Over. Player 2 wins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing value function iteratively...\n",
      "Initializing value function iteratively...\n"
     ]
    }
   ],
   "source": [
    "env = Environment()\n",
    "p1 = Agent(0.3, 0.3, env.x, True)\n",
    "p2 = Agent(0.3, 0.3, env.o, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play_game(p1, p2, env, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play games for the given number of episodes and update the value functions after every game\n",
    "def train_agents(p1, p2, env, episodes = 10000, verbose = False):\n",
    "    p1.set_verbose(verbose)\n",
    "    p2.set_verbose(verbose)\n",
    "    for ep in range(episodes):\n",
    "        # Alternate the starters, so that each player learns both how to attack and defend\n",
    "        r = np.random.random()\n",
    "        if r < 0.5:\n",
    "            play_game(p1, p2, env, verbose)\n",
    "        else:\n",
    "            play_game(p2, p1, env, verbose)\n",
    "        # update the value functions, then reset state histories for a new game\n",
    "        p1.update()\n",
    "        p2.update()\n",
    "        p1.reset_history()\n",
    "        p2.reset_history()\n",
    "        # reset the board for the next game\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agents(p1, p2, env, episodes = 1000, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1 turn:\n",
      "Finding action with maximum value\n",
      "-------------------------\n",
      "|  0.45 |  0.46 |  0.45 |\n",
      "-------------------------\n",
      "|  0.46 |  0.58 |  0.42 |\n",
      "-------------------------\n",
      "|  0.46 |  0.43 |  0.46 |\n",
      "-------------------------\n",
      "-------------------------\n",
      "|       |       |       |\n",
      "-------------------------\n",
      "|       |   x   |       |\n",
      "-------------------------\n",
      "|       |       |       |\n",
      "-------------------------\n",
      "Player 2 turn:\n",
      "Finding action with maximum value\n",
      "-------------------------\n",
      "|  0.38 |  0.38 |  0.40 |\n",
      "-------------------------\n",
      "|  0.42 |   x   |  0.41 |\n",
      "-------------------------\n",
      "|  0.40 |  0.40 |  0.42 |\n",
      "-------------------------\n",
      "-------------------------\n",
      "|       |       |       |\n",
      "-------------------------\n",
      "|   o   |   x   |       |\n",
      "-------------------------\n",
      "|       |       |       |\n",
      "-------------------------\n",
      "Player 1 turn:\n",
      "Finding action with maximum value\n",
      "-------------------------\n",
      "|  0.53 |  0.55 |  0.50 |\n",
      "-------------------------\n",
      "|   o   |   x   |  0.50 |\n",
      "-------------------------\n",
      "|  0.58 |  0.68 |  0.45 |\n",
      "-------------------------\n",
      "-------------------------\n",
      "|       |       |       |\n",
      "-------------------------\n",
      "|   o   |   x   |       |\n",
      "-------------------------\n",
      "|       |   x   |       |\n",
      "-------------------------\n",
      "Player 2 turn:\n",
      "Finding action with maximum value\n",
      "-------------------------\n",
      "|  0.45 |  0.47 |  0.39 |\n",
      "-------------------------\n",
      "|   o   |   x   |  0.14 |\n",
      "-------------------------\n",
      "|  0.35 |   x   |  0.13 |\n",
      "-------------------------\n",
      "-------------------------\n",
      "|       |   o   |       |\n",
      "-------------------------\n",
      "|   o   |   x   |       |\n",
      "-------------------------\n",
      "|       |   x   |       |\n",
      "-------------------------\n",
      "Player 1 turn:\n",
      "Finding action with maximum value\n",
      "-------------------------\n",
      "|  0.50 |   o   |  0.50 |\n",
      "-------------------------\n",
      "|   o   |   x   |  0.50 |\n",
      "-------------------------\n",
      "|  0.56 |   x   |  0.50 |\n",
      "-------------------------\n",
      "-------------------------\n",
      "|       |   o   |       |\n",
      "-------------------------\n",
      "|   o   |   x   |       |\n",
      "-------------------------\n",
      "|   x   |   x   |       |\n",
      "-------------------------\n",
      "Player 2 turn:\n",
      "Finding action with maximum value\n",
      "-------------------------\n",
      "|  0.44 |   o   |  0.38 |\n",
      "-------------------------\n",
      "|   o   |   x   |  0.50 |\n",
      "-------------------------\n",
      "|   x   |   x   |  0.50 |\n",
      "-------------------------\n",
      "-------------------------\n",
      "|       |   o   |       |\n",
      "-------------------------\n",
      "|   o   |   x   |   o   |\n",
      "-------------------------\n",
      "|   x   |   x   |       |\n",
      "-------------------------\n",
      "Player 1 turn:\n",
      "Finding action with maximum value\n",
      "-------------------------\n",
      "|  0.50 |   o   |  1.00 |\n",
      "-------------------------\n",
      "|   o   |   x   |   o   |\n",
      "-------------------------\n",
      "|   x   |   x   |  1.00 |\n",
      "-------------------------\n",
      "-------------------------\n",
      "|       |   o   |   x   |\n",
      "-------------------------\n",
      "|   o   |   x   |   o   |\n",
      "-------------------------\n",
      "|   x   |   x   |       |\n",
      "-------------------------\n",
      "Game Over. Player 1 wins\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "p1.set_verbose(True)\n",
    "p2.set_verbose(True)\n",
    "play_game(p1, p2, env, verbose = True, training_mode = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the take_human_action method, which is more appropriate for human players\n",
    "class Human(Agent):\n",
    "    def __init__(self, symbol):\n",
    "        super().__init__(0,0,symbol)\n",
    "    # This function will ask the human player for his actions, instead of choosing them greedily\n",
    "    def take_human_action(self, env, training_mode = False):\n",
    "        # find the posible actions (empty cells) the agent can take\n",
    "        actions = []\n",
    "        values = []\n",
    "        for i in range(LENGTH):\n",
    "            for j in range(LENGTH):\n",
    "                if env.board[i, j] == 0:\n",
    "                    actions.append((i, j))\n",
    "        # Ask for the human player's action, given as a double digit integer\n",
    "        #    e.g.: 21 corresponds to action (2, 1)\n",
    "        print('Enter action:', end = ' ')\n",
    "        action_str = input()\n",
    "        i = int(action_str[0])\n",
    "        j = int(action_str[1])\n",
    "        action = (i, j)\n",
    "        # Keep asking for a new action if the given one is not valid\n",
    "        while not action in actions:\n",
    "            print('Invalid action!')\n",
    "            print('Enter another action:', end = ' ')\n",
    "            action_str = input()\n",
    "            i = int(action_str[0])\n",
    "            j = int(action_str[1])\n",
    "            action = (i, j)\n",
    "            \n",
    "        # Place symbol on the selected action\n",
    "        env.board[action] = self.symbol\n",
    "        \n",
    "        # Update state history (not really necessary here)\n",
    "        self.update_state_history(env.get_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "human = Human(env.o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will handle games between ai and human better (or human and human)\n",
    "def play_vs_human(p1, p2, env, verbose = True):\n",
    "    env.reset()\n",
    "    while not env.game_over():\n",
    "        if verbose:\n",
    "            print('Player 1 turn:')\n",
    "            \n",
    "        # use take_action if ai playing, or take_human_action if human playing\n",
    "        if isinstance(p1, Human):\n",
    "            p1.take_human_action(env, False)\n",
    "        else:\n",
    "            p1.take_action(env, False)\n",
    "            \n",
    "        if verbose:\n",
    "            env.draw_board()\n",
    "        \n",
    "        # If player 1 won already, no need for player 2 to play\n",
    "        if env.game_over():\n",
    "            break\n",
    "            \n",
    "        if verbose:\n",
    "            print('Player 2 turn:')\n",
    "        \n",
    "        # use take_action if ai playing, or take_human_action if human playing\n",
    "        if isinstance(p2, Human):\n",
    "            p2.take_human_action(env, False)\n",
    "        else:\n",
    "            p2.take_action(env, False)\n",
    "            \n",
    "        if verbose:\n",
    "            env.draw_board()\n",
    "    # print results\n",
    "    if verbose:\n",
    "        if env.winner == None:\n",
    "            print('Game Over. Draw')\n",
    "        elif env.winner == p1.symbol:\n",
    "            print('Game Over. Player 1 wins')\n",
    "        else:\n",
    "            print('Game Over. Player 2 wins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1 turn:\n",
      "Enter action: 11\n",
      "-------------------------\n",
      "|       |       |       |\n",
      "-------------------------\n",
      "|       |   o   |       |\n",
      "-------------------------\n",
      "|       |       |       |\n",
      "-------------------------\n",
      "Player 2 turn:\n",
      "-------------------------\n",
      "|       |       |       |\n",
      "-------------------------\n",
      "|   x   |   o   |       |\n",
      "-------------------------\n",
      "|       |       |       |\n",
      "-------------------------\n",
      "Player 1 turn:\n",
      "Enter action: 20\n",
      "-------------------------\n",
      "|       |       |       |\n",
      "-------------------------\n",
      "|   x   |   o   |       |\n",
      "-------------------------\n",
      "|   o   |       |       |\n",
      "-------------------------\n",
      "Player 2 turn:\n",
      "-------------------------\n",
      "|       |       |   x   |\n",
      "-------------------------\n",
      "|   x   |   o   |       |\n",
      "-------------------------\n",
      "|   o   |       |       |\n",
      "-------------------------\n",
      "Player 1 turn:\n",
      "Enter action: 21\n",
      "-------------------------\n",
      "|       |       |   x   |\n",
      "-------------------------\n",
      "|   x   |   o   |       |\n",
      "-------------------------\n",
      "|   o   |   o   |       |\n",
      "-------------------------\n",
      "Player 2 turn:\n",
      "-------------------------\n",
      "|   x   |       |   x   |\n",
      "-------------------------\n",
      "|   x   |   o   |       |\n",
      "-------------------------\n",
      "|   o   |   o   |       |\n",
      "-------------------------\n",
      "Player 1 turn:\n",
      "Enter action: 22\n",
      "-------------------------\n",
      "|   x   |       |   x   |\n",
      "-------------------------\n",
      "|   x   |   o   |       |\n",
      "-------------------------\n",
      "|   o   |   o   |   o   |\n",
      "-------------------------\n",
      "Game Over. Player 1 wins\n"
     ]
    }
   ],
   "source": [
    "play_vs_human(human, p1, env, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = Human(env.x)\n",
    "h2 = Human(env.o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1 turn:\n",
      "Enter action: 00\n",
      "-------------------------\n",
      "|   x   |       |       |\n",
      "-------------------------\n",
      "|       |       |       |\n",
      "-------------------------\n",
      "|       |       |       |\n",
      "-------------------------\n",
      "Player 2 turn:\n",
      "Enter action: 11\n",
      "-------------------------\n",
      "|   x   |       |       |\n",
      "-------------------------\n",
      "|       |   o   |       |\n",
      "-------------------------\n",
      "|       |       |       |\n",
      "-------------------------\n",
      "Player 1 turn:\n",
      "Enter action: 02\n",
      "-------------------------\n",
      "|   x   |       |   x   |\n",
      "-------------------------\n",
      "|       |   o   |       |\n",
      "-------------------------\n",
      "|       |       |       |\n",
      "-------------------------\n",
      "Player 2 turn:\n",
      "Enter action: 01\n",
      "-------------------------\n",
      "|   x   |   o   |   x   |\n",
      "-------------------------\n",
      "|       |   o   |       |\n",
      "-------------------------\n",
      "|       |       |       |\n",
      "-------------------------\n",
      "Player 1 turn:\n",
      "Enter action: 21\n",
      "-------------------------\n",
      "|   x   |   o   |   x   |\n",
      "-------------------------\n",
      "|       |   o   |       |\n",
      "-------------------------\n",
      "|       |   x   |       |\n",
      "-------------------------\n",
      "Player 2 turn:\n",
      "Enter action: 00\n",
      "Invalid action!\n",
      "Enter another action: 10\n",
      "-------------------------\n",
      "|   x   |   o   |   x   |\n",
      "-------------------------\n",
      "|   o   |   o   |       |\n",
      "-------------------------\n",
      "|       |   x   |       |\n",
      "-------------------------\n",
      "Player 1 turn:\n",
      "Enter action: 12\n",
      "-------------------------\n",
      "|   x   |   o   |   x   |\n",
      "-------------------------\n",
      "|   o   |   o   |   x   |\n",
      "-------------------------\n",
      "|       |   x   |       |\n",
      "-------------------------\n",
      "Player 2 turn:\n",
      "Enter action: 22\n",
      "-------------------------\n",
      "|   x   |   o   |   x   |\n",
      "-------------------------\n",
      "|   o   |   o   |   x   |\n",
      "-------------------------\n",
      "|       |   x   |   o   |\n",
      "-------------------------\n",
      "Player 1 turn:\n",
      "Enter action: 20\n",
      "-------------------------\n",
      "|   x   |   o   |   x   |\n",
      "-------------------------\n",
      "|   o   |   o   |   x   |\n",
      "-------------------------\n",
      "|   x   |   x   |   o   |\n",
      "-------------------------\n",
      "Game Over. Draw\n"
     ]
    }
   ],
   "source": [
    "play_vs_human(h1, h2, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
